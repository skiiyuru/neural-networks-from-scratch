{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Our First Neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single Neuron\n",
    "\n",
    "All the neuron does is take the fractions of inputs, where these fractions (weights) are the adjustable parameters, and adds another adjustable parameter ‚Äî the bias ‚Äî then outputs the result.\n",
    "\n",
    "![single-neuron](images/Screenshot_20230218_090103.png)\n",
    "\n",
    "Lets see it in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neuron\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "weights = [0.2, 0.8, -0.5, 1.0] \n",
    "bias = 2.0\n",
    "\n",
    "output = (inputs[0]*weights[0] + \n",
    "          inputs[1]*weights[1] + \n",
    "          inputs[2]*weights[2] + \n",
    "          inputs[3]*weights[3] + \n",
    "          bias)\n",
    "\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Layer of Neurons\n",
    "\n",
    "Layers are just groups of neurons. Each neuron in a layer:\n",
    "* Takes exactly the same input\n",
    "* Has its own set of weights\n",
    "* Has its own output\n",
    "\n",
    "![layer](images/Screenshot_20230216_215212.png)\n",
    "\n",
    "Thus the output of a layer then becomes a group of outputs from its neurons\n",
    "\n",
    "Lets see it in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 1.21, 2.385]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for all neurons\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "\n",
    "# for 1st neuron\n",
    "weights1 = [0.2, 0.8, -0.5, 1] \n",
    "bias1 = 2 \n",
    "\n",
    "# for 2nd neuron\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5] \n",
    "bias2 = 3 \n",
    "\n",
    "# for 3rd neuron\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87] \n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [# for 1st neuron\n",
    "           inputs[0]*weights1[0] + \n",
    "           inputs[1]*weights1[1] + \n",
    "           inputs[2]*weights1[2] + \n",
    "           inputs[3]*weights1[3] + bias1, \n",
    "           # for 2nd neuron\n",
    "           inputs[0]*weights2[0] + \n",
    "           inputs[1]*weights2[1] + \n",
    "           inputs[2]*weights2[2] + \n",
    "           inputs[3]*weights2[3] + bias2, \n",
    "           # for 3rd neuron\n",
    "           inputs[0]*weights3[0] + \n",
    "           inputs[1]*weights3[1] + \n",
    "           inputs[2]*weights3[2] + \n",
    "           inputs[3]*weights3[3] + bias3]\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine coding a layer with 20 neurons. Using the approach from the code above would be tideous. \n",
    "\n",
    "Lets refactor the code to be more dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 1.21, 2.385]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for weight_set, bias in  zip(weights, biases):\n",
    "    output = 0\n",
    "    for input, weight in zip(inputs, weight_set):\n",
    "        output += input*weight\n",
    "    output +=bias\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our code can calculate the output of a layer of any number of neurons.\n",
    "\n",
    "However, python alone doesn't do array math very well. So let's upgrade to **Numpy**üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Single Neuron with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "weights = [0.2, 0.8, -0.5, 1.0] \n",
    "bias = 2.0 \n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "\n",
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer of Neurons with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8  , 1.21 , 2.385])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer of Neurons & Batches of Data\n",
    "\n",
    "Think of the inputs as samples from our server monitoring scenario. Let‚Äôs say you have sensor data for the server with metrics such as upload/download rates, temperature, and humidity, all organized by time for every 10 minutes.\n",
    "\n",
    "Each column in a singel input is a value for a feature.\n",
    "\n",
    "A single sample => [üå°Ô∏è, ‚¨áÔ∏è-rate, ‚¨ÜÔ∏è-rate, üíß]\n",
    "\n",
    "The input layer of a neural network will have a total number of neurons equal to the total number of features\n",
    "\n",
    "`len(input_layer) == len(features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11724/1571184134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mlayer_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# A input batch of 3 samples\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# A layer of 3 neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(inputs, weights) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Multiplication\n",
    "\n",
    "![array-multiplication](images/Screenshot_20230220_081537.png)\n",
    "\n",
    "Notice that the length of the row in the first array has to match the length of the column of the second array\n",
    "\n",
    "Going back to our code, you can now see that the rows in `inputs` are of length 4 but the columns in `weigths` are of length 3.\n",
    "\n",
    "That is why we get the shape error\n",
    "\n",
    "To fix this, we need to switch the rows and columns of `weights` so that we can satisfy the above rule. This operation is known as **transposing**\n",
    "\n",
    "Numpy arrays have a `T` (transpose) attribute that we can use. But first we have to transform `weights` which is currently a python list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A input batch of 3 samples\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# A layer of 3 neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37a1ae08f87caea64dd701a1ac68668d202b597d9c5a67183a139e8ada6ac175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
