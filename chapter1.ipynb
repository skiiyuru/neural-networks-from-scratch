{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Our First Neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single Neuron\n",
    "\n",
    "![single-neuron](images/Screenshot_20230218_090103.png)\n",
    "\n",
    "This neuron sums each input multiplied by that input‚Äôs weight, then adds the bias.\n",
    "\n",
    "Lets see it in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neuron\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "weights = [0.2, 0.8, -0.5, 1.0] \n",
    "bias = 2.0\n",
    "\n",
    "output = (inputs[0]*weights[0] + \n",
    "          inputs[1]*weights[1] + \n",
    "          inputs[2]*weights[2] + \n",
    "          inputs[3]*weights[3] + \n",
    "          bias)\n",
    "\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Layer of Neurons\n",
    "\n",
    "Layers are just groups of neurons. Each neuron in a layer:\n",
    "* Takes exactly the same input\n",
    "* Has its own set of weights\n",
    "* Has its own output\n",
    "\n",
    "![layer](images/Screenshot_20230216_215212.png)\n",
    "\n",
    "Thus the output of a layer then becomes a group of outputs from its neurons\n",
    "\n",
    "Lets see it in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 1.21, 2.385]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for all neurons\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "\n",
    "# for 1st neuron\n",
    "weights1 = [0.2, 0.8, -0.5, 1] \n",
    "bias1 = 2 \n",
    "\n",
    "# for 2nd neuron\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5] \n",
    "bias2 = 3 \n",
    "\n",
    "# for 3rd neuron\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87] \n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [# for 1st neuron\n",
    "           inputs[0]*weights1[0] + \n",
    "           inputs[1]*weights1[1] + \n",
    "           inputs[2]*weights1[2] + \n",
    "           inputs[3]*weights1[3] + bias1, \n",
    "           # for 2nd neuron\n",
    "           inputs[0]*weights2[0] + \n",
    "           inputs[1]*weights2[1] + \n",
    "           inputs[2]*weights2[2] + \n",
    "           inputs[3]*weights2[3] + bias2, \n",
    "           # for 3rd neuron\n",
    "           inputs[0]*weights3[0] + \n",
    "           inputs[1]*weights3[1] + \n",
    "           inputs[2]*weights3[2] + \n",
    "           inputs[3]*weights3[3] + bias3]\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine coding a layer with 20 neurons. Using the approach from the code above would be tideous. \n",
    "\n",
    "Lets refactor the code to be more dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 1.21, 2.385]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "# put all the weights togethor as a list of lists\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "# put all the biases togethor as a list\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for weight_set, bias in  zip(weights, biases):\n",
    "    output = 0\n",
    "    for input, weight in zip(inputs, weight_set):\n",
    "        output += input*weight\n",
    "    output +=bias\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our code can calculate the output of a layer of any number of neurons.\n",
    "\n",
    "However, python alone doesn't do array math very well. So let's upgrade to **Numpy**üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Single Neuron with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "weights = [0.2, 0.8, -0.5, 1.0] \n",
    "bias = 2.0 \n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "\n",
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer of Neurons with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8  , 1.21 , 2.385])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5] \n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer of Neurons & Batches of Data\n",
    "\n",
    "Think of the inputs as samples from our server monitoring scenario. Let‚Äôs say you have sensor data for the server with metrics such as:\n",
    "  * upload rates (‚¨ÜÔ∏è)\n",
    "  * download rates (‚¨áÔ∏è)\n",
    "  * temperature (üå°Ô∏è)\n",
    "  * humidity (üíß)\n",
    "\n",
    "...all organized by time for every 10 minutes.\n",
    "\n",
    "Each column in a single sample is a value for a feature.\n",
    "\n",
    "columns => [‚¨áÔ∏è, ‚¨ÜÔ∏è, üå°Ô∏è, üíß]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11724/1571184134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mlayer_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# A input batch of 3 samples\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# A layer of 3 neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(inputs, weights) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "![array-multiplication](images/Screenshot_20230220_081537.png)\n",
    "\n",
    "Notice that the length of the row in the first array has to match the length of the column of the second array\n",
    "\n",
    "Going back to our code, you can now see that the rows in `inputs` are of length 4 but the columns in `weigths` are of length 3.\n",
    "\n",
    "That is why we get the shape error.\n",
    "\n",
    "To fix this, we need to switch the rows and columns of `weights` so that we can satisfy the above rule. This operation is known as **transposing**\n",
    "\n",
    "Numpy arrays have a `T` (transpose) attribute that we can use. But first we have to transform `weights` which is currently a python list to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A input batch of 3 samples\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# A layer of 3 neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] \n",
    "           \n",
    "biases = [2.0, 3.0, 0.5] \n",
    "\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:**\n",
    "* When adding the dot product resuslt to `biases`, the biases vector gets added to each row of the result. Let's visualize this\n",
    "\n",
    "![array-addition](images/Screenshot_20230220_134626.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5031 , -1.04185, -2.03875],\n",
       "       [ 0.2434 , -2.7332 , -5.7633 ],\n",
       "       [-0.99314,  1.41254, -0.35655]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A input batch of 3 samples\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# Hidden layer 1 (3 neurons)\n",
    "weights1 = [[0.2, 0.8, -0.5, 1], \n",
    "            [0.5, -0.91, 0.26, -0.5], \n",
    "            [-0.26, -0.27, 0.17, 0.87]] \n",
    "biases1 = [2.0, 3.0, 0.5] \n",
    "\n",
    "# Hidden layer 2 (3 neurons)\n",
    "weights2 = [[0.1, -0.14, 0.5], \n",
    "            [-0.5, 0.12, -0.33], \n",
    "            [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights1).T) + biases1\n",
    "\n",
    "# output from the input layer becomes input for the hidden layer\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "layer2_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upgrade our code to use object oriented programming priniciples. üí™\n",
    "\n",
    "First, lets create a class for a layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class Layer_Dense:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_inputs : int\n",
    "        Number of features in a single sample\n",
    "    n_neurons : int\n",
    "        Number of neurons\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # we multiply by 0.10 so that we get values between -0.1 and 0.1\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons) \n",
    "        self.biases = np.zeros(shape=(1, n_neurons))\n",
    "        pass\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:**\n",
    "\n",
    "We create our weights matrix using `randn` and specify a shape of (`n_inputs`, `n_neurons`)\n",
    "\n",
    "So in our previous multiple layers model, this would result in a `weights` of shape (4,3). However the original weights matrix was (3, 4). \n",
    "\n",
    "So why are we setting weights like this in the class?\n",
    "  * So that we can skip the transpose operation we were doing earlier on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4105985 ,  0.14404357,  1.45427351],\n",
       "       [ 0.76103773,  0.12167502,  0.44386323],\n",
       "       [ 0.33367433,  1.49407907, -0.20515826],\n",
       "       [ 0.3130677 , -0.85409574, -2.55298982]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06536186,  0.08644362, -0.0742165 ],\n",
       "       [ 0.22697546, -0.14543657,  0.00457585],\n",
       "       [-0.01871839,  0.15327792,  0.14693588],\n",
       "       [ 0.01549474,  0.03781625, -0.08877857]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.10 * np.random.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46060065,  0.49553499,  0.08326609, -0.4587313 ,  0.34089788],\n",
       "       [-1.22200575,  0.36184486,  0.40854986,  0.73857089,  1.16296097],\n",
       "       [ 0.02889447, -0.05931761, -0.56936475, -0.09750155, -0.03436311]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1.0, 2.0, 3.0, 2.5],\n",
    "     [2.0, 5.0, -1.0, 2.0],\n",
    "     [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "layer1 = Layer_Dense(n_inputs=4, n_neurons=5)\n",
    "layer1.forward(inputs=X)\n",
    "layer1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03570317, -0.0702464 ],\n",
       "       [ 0.086899  ,  0.09347172],\n",
       "       [-0.02322913, -0.06128466]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 = Layer_Dense(n_inputs=5, n_neurons=2)\n",
    "layer2.forward(inputs=layer1.output)\n",
    "layer2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37a1ae08f87caea64dd701a1ac68668d202b597d9c5a67183a139e8ada6ac175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
